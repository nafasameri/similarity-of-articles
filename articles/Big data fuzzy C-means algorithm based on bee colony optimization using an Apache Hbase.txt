Title: Big data fuzzy C-means algorithm based on bee colony optimization using an Apache Hbase
Keywords: 
Citation: 8
Abstract: Clustering algorithm analysis, including time and space complexity analysis, has always been discussed in the literature. The emergence of big data has also created a lot of challenges for this issue. Because of high complexity and execution time, traditional clustering techniques cannot be used for such an amount of data. This problem has been addressed in this research. To present the clustering algorithm using a bee colony algorithm and high-speed read/write performance, Map-Reduce architecture is used. Using this architecture allows the proposed method to cluster any volume of data, and there is no limit to the amount of data. The presented algorithm has good performance and high precision. The simulation results on 3 datasets show that the presented algorithm is more efficient than other big data clustering methods. Also, the results of our algorithm execution time on huge datasets are much …

Tokens: ['big', 'data', 'fuzzy', 'c-means', 'algorithm', 'based', 'on', 'bee', 'colony', 'optimization', 'using', 'an', 'apache', 'hbase', 'clustering', 'algorithm', 'analysis', 'including', 'time', 'and', 'space', 'complexity', 'analysis', 'has', 'always', 'been', 'discussed', 'in', 'the', 'literature', 'the', 'emergence', 'of', 'big', 'data', 'has', 'also', 'created', 'a', 'lot', 'of', 'challenges', 'for', 'this', 'issue', 'because', 'of', 'high', 'complexity', 'and', 'execution', 'time', 'traditional', 'clustering', 'techniques', 'can', 'not', 'be', 'used', 'for', 'such', 'an', 'amount', 'of', 'data', 'this', 'problem', 'has', 'been', 'addressed', 'in', 'this', 'research', 'to', 'present', 'the', 'clustering', 'algorithm', 'using', 'a', 'bee', 'colony', 'algorithm', 'and', 'high-speed', 'read/write', 'performance', 'map-reduce', 'architecture', 'is', 'used', 'using', 'this', 'architecture', 'allows', 'the', 'proposed', 'method', 'to', 'cluster', 'any', 'volume', 'of', 'data', 'and', 'there', 'is', 'no', 'limit', 'to', 'the', 'amount', 'of', 'data', 'the', 'presented', 'algorithm', 'has', 'good', 'performance', 'and', 'high', 'precision', 'the', 'simulation', 'results', 'on', 'datasets', 'show', 'that', 'the', 'presented', 'algorithm', 'is', 'more', 'efficient', 'than', 'other', 'big', 'data', 'clustering', 'methods', 'also', 'the', 'results', 'of', 'our', 'algorithm', 'execution', 'time', 'on', 'huge', 'datasets', 'are', 'much', '…']
Term Ferquency: <FreqDist with 60 samples and 94 outcomes>
TF-IDF:    addressed  algorithm   allows     also   always   amount       an  analysis     and      any   apache  architecture      are    based       be  because      bee     been      big   cannot  challenges  cluster  clustering   colony  complexity  created     data  datasets  discussed  efficient  emergence  execution      for    fuzzy     good      has    hbase     high     huge       in  including       is    issue    limit  literature      lot      map    means   method  methods     more     much       no       of       on  optimization    other      our  performance  precision  present  presented  problem  proposed     read   reduce  research  results     show  simulation    space    speed     such  techniques     than     that      the    there     this     time       to  traditional     used    using   volume    write
0    0.04598    0.32186  0.04598  0.09196  0.04598  0.09196  0.09196   0.09196  0.2299  0.04598  0.04598       0.09196  0.04598  0.04598  0.04598  0.04598  0.09196  0.09196  0.13794  0.04598     0.04598  0.04598     0.18392  0.09196     0.09196  0.04598  0.27588   0.09196    0.04598    0.04598    0.04598    0.09196  0.09196  0.04598  0.04598  0.18392  0.04598  0.13794  0.04598  0.09196    0.04598  0.13794  0.04598  0.04598     0.04598  0.04598  0.04598  0.04598  0.04598  0.04598  0.04598  0.04598  0.04598  0.32186  0.13794       0.04598  0.04598  0.04598      0.09196    0.04598  0.04598    0.09196  0.04598   0.04598  0.04598  0.04598   0.04598  0.09196  0.04598     0.04598  0.04598  0.04598  0.04598     0.04598  0.04598  0.04598  0.41382  0.04598  0.18392  0.13794  0.13794      0.04598  0.09196  0.13794  0.04598  0.04598
